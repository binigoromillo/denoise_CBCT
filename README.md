# denoise_CBCT

### SUMMARY

Breast CT (bCT) systems, based on cone-beam CT (CBCT) geometries with high-resolution flat-panel detectors, have been developed over the last ~15 years. Clinical bCT studies showed that the true volumetric information in bCT provided excellent visualization of soft tissue features and improved capability for detection and characterization of cancerous lesions, compared to 2D mammography or to digital breast tomosynthesis, at comparable radiation dose. However, at equidose conditions, bCT results in increased image noise from lower exposure in individual projection views and from amplification of high frequencies caused by the filtering stage in filtered backprojection reconstruction algorithms, commonly used for bCT image reconstruction. Recent developments in deep convolutional neural networks (CNNs) for data-driven image restoration, have shown great potential for denoising in photographic and in x-ray CT and CBCT imaging.

Deep learning (DL) denoising networkshave been conventionally trained using supervised approaches that minimize the mean squared error (MSE) loss, computed between the CNN inference, with a normal (or low) dose (ND) image as input, and a matched high-dose (HD) target, within the Noise2Clean paradigm. However, such matched datasets are rarely available. The dual noise level requirement was relaxed with the introduction of the Noise2Noise strategy, that proved that minimization of MSE across pairs of noisy
images with zero-mean independent and identically distributed (i.i.d.) noise realizations, and matched image content, converged to an equivalent solution. While more attainable, acquisition of two matched scans of the same patient is seldom feasible in clinical bCT. Self-supervised training approaches aim at alleviating the need for paired noise realizations by building loss functions employing targets derived from the noisy input that act surrogates of the clean signal. Self-supervised strategies demonstrated denoising performance comparable to Noise2Clean in photographic imaging, but their performance is impacted by the correlated nature of noise in CT (and bCT), arising from correlation between the noise in neighboring detector pixels and from correlations introduced by the backprojection operator. 

The previous work of this project has focused on characterizing the impact of bCT noise correlation on self-supervised DL denoising leveraging high-fidelity models of the bCT imaging chain. This work was published in SPIE (Society of Photographic Instrumentation Engineers). The paper can be found here: https://drive.google.com/file/d/1P02st7aWHB-bjU8yjKq541RabqAiJVHu/view?usp=sharing

As an alternative self-supervised denoising algorithm, we implement here some approaches that have been proven effective in denoising **projection data** for low-dose cone beam CT of head and neck. (https://drive.google.com/file/d/1QdhSBntcSWq73WjSTUG_4njJU7wnKmYL/view?usp=sharing)

In this case, 
